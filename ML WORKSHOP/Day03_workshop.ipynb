{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d29cbb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\student\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\student\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\student\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\student\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e180346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, roc_auc_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31805238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('C:/Users/Student/Desktop/ML WORKSHOP/IMDb_Reviews.csv')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc5d6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(n = 25000, random_state = 42)  # Adjust the value of n as needed\n",
    "\n",
    "# Reset index\n",
    "dataset.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c0cf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>More directors like Nacho Vigalondo need a gre...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Rita Hayworth lights up the screen in this fun...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>The biggest heroes, is one of the greatest mov...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>I happened to see a promo for this movie on Sp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Dumb is as dumb does, in this thoroughly unint...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      I really liked this Summerslam due to the look...  positive\n",
       "1      Not many television shows appeal to quite as m...  positive\n",
       "2      The film quickly gets to a major chase scene w...  negative\n",
       "3      Jane Austen would definitely approve of this o...  positive\n",
       "4      Expectations were somewhat high for me when I ...  negative\n",
       "...                                                  ...       ...\n",
       "24995  More directors like Nacho Vigalondo need a gre...  positive\n",
       "24996  Rita Hayworth lights up the screen in this fun...  positive\n",
       "24997  The biggest heroes, is one of the greatest mov...  positive\n",
       "24998  I happened to see a promo for this movie on Sp...  negative\n",
       "24999  Dumb is as dumb does, in this thoroughly unint...  negative\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a01f3428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe7618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Duplicates: 124\n",
      "Number Of Duplicates after drop: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number Of Duplicates:\", dataset.duplicated().sum())\n",
    "dataset.drop_duplicates(inplace = True)\n",
    "print(\"Number Of Duplicates after drop:\", dataset.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b24d58f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    12495\n",
      "negative    12381\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Sentiment Distribution'}, xlabel='sentiment'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dataset['sentiment'].value_counts())\n",
    "dataset['sentiment'].value_counts().plot(kind = 'bar', title = 'Sentiment Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80b3ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['review'] = dataset['review'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8726ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'),\"\",raw_text)\n",
    "    return cleaned_text\n",
    "dataset['review'] = dataset['review'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dd6602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(raw_text):\n",
    "    cleaned_text = re.sub(r'http[s]?://\\S+', '', raw_text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply the function to your dataset\n",
    "dataset['review'] = dataset['review'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee58f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    for c in string.punctuation:\n",
    "        text = text.replace(c,'')\n",
    "    return text\n",
    "dataset['review'] = dataset['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9586511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "sw_list = stopwords.words('english')\n",
    "dataset['review'] = dataset['review'].apply(\n",
    "    lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c24632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>really liked summerslam due look arena curtain...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many television shows appeal quite many differ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film quickly gets major chase scene ever incre...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jane austen would definitely approve onegwynet...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expectations somewhat high went see movie thou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>barely find words express utterly utterly awfu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>directors like nacho vigalondo need greater ou...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>rita hayworth lights screen fun fancy delightf...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>biggest heroes one greatest movies ever good s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>happened see promo movie spike channel last ni...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      really liked summerslam due look arena curtain...  positive\n",
       "1      many television shows appeal quite many differ...  positive\n",
       "2      film quickly gets major chase scene ever incre...  negative\n",
       "3      jane austen would definitely approve onegwynet...  positive\n",
       "4      expectations somewhat high went see movie thou...  negative\n",
       "...                                                  ...       ...\n",
       "24994  barely find words express utterly utterly awfu...  negative\n",
       "24995  directors like nacho vigalondo need greater ou...  positive\n",
       "24996  rita hayworth lights screen fun fancy delightf...  positive\n",
       "24997  biggest heroes one greatest movies ever good s...  positive\n",
       "24998  happened see promo movie spike channel last ni...  negative\n",
       "\n",
       "[24876 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d44e2d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "dataset['review'] = dataset['review'].apply(lambda sentence: word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16dba776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['really',\n",
       " 'liked',\n",
       " 'summerslam',\n",
       " 'due',\n",
       " 'look',\n",
       " 'arena',\n",
       " 'curtains',\n",
       " 'look',\n",
       " 'overall',\n",
       " 'interesting',\n",
       " 'reason',\n",
       " 'anyways',\n",
       " 'could',\n",
       " 'one',\n",
       " 'best',\n",
       " 'summerslams',\n",
       " 'ever',\n",
       " 'wwf',\n",
       " 'didnt',\n",
       " 'lex',\n",
       " 'luger',\n",
       " 'main',\n",
       " 'event',\n",
       " 'yokozuna',\n",
       " 'time',\n",
       " 'ok',\n",
       " 'huge',\n",
       " 'fat',\n",
       " 'man',\n",
       " 'vs',\n",
       " 'strong',\n",
       " 'man',\n",
       " 'im',\n",
       " 'glad',\n",
       " 'times',\n",
       " 'changed',\n",
       " 'terrible',\n",
       " 'main',\n",
       " 'event',\n",
       " 'like',\n",
       " 'every',\n",
       " 'match',\n",
       " 'luger',\n",
       " 'terrible',\n",
       " 'matches',\n",
       " 'card',\n",
       " 'razor',\n",
       " 'ramon',\n",
       " 'vs',\n",
       " 'ted',\n",
       " 'dibiase',\n",
       " 'steiner',\n",
       " 'brothers',\n",
       " 'vs',\n",
       " 'heavenly',\n",
       " 'bodies',\n",
       " 'shawn',\n",
       " 'michaels',\n",
       " 'vs',\n",
       " 'curt',\n",
       " 'hening',\n",
       " 'event',\n",
       " 'shawn',\n",
       " 'named',\n",
       " 'big',\n",
       " 'monster',\n",
       " 'body',\n",
       " 'guard',\n",
       " 'diesel',\n",
       " 'irs',\n",
       " 'vs',\n",
       " '123',\n",
       " 'kid',\n",
       " 'bret',\n",
       " 'hart',\n",
       " 'first',\n",
       " 'takes',\n",
       " 'doink',\n",
       " 'takes',\n",
       " 'jerry',\n",
       " 'lawler',\n",
       " 'stuff',\n",
       " 'harts',\n",
       " 'lawler',\n",
       " 'always',\n",
       " 'interesting',\n",
       " 'ludvig',\n",
       " 'borga',\n",
       " 'destroyed',\n",
       " 'marty',\n",
       " 'jannetty',\n",
       " 'undertaker',\n",
       " 'took',\n",
       " 'giant',\n",
       " 'gonzalez',\n",
       " 'another',\n",
       " 'terrible',\n",
       " 'match',\n",
       " 'smoking',\n",
       " 'gunns',\n",
       " 'tatanka',\n",
       " 'took',\n",
       " 'bam',\n",
       " 'bam',\n",
       " 'bigelow',\n",
       " 'headshrinkers',\n",
       " 'yokozuna',\n",
       " 'defended',\n",
       " 'world',\n",
       " 'title',\n",
       " 'lex',\n",
       " 'luger',\n",
       " 'match',\n",
       " 'boring',\n",
       " 'terrible',\n",
       " 'ending',\n",
       " 'however',\n",
       " 'deserves',\n",
       " '810']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "569aaaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[really, liked, summerslam, due, look, arena, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[many, television, shows, appeal, quite, many,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[film, quickly, gets, major, chase, scene, eve...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[jane, austen, would, definitely, approve, one...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[expectations, somewhat, high, went, see, movi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>[barely, find, words, express, utterly, utterl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>[directors, like, nacho, vigalondo, need, grea...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>[rita, hayworth, lights, screen, fun, fancy, d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>[biggest, heroes, one, greatest, movies, ever,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>[happened, see, promo, movie, spike, channel, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      [really, liked, summerslam, due, look, arena, ...  positive\n",
       "1      [many, television, shows, appeal, quite, many,...  positive\n",
       "2      [film, quickly, gets, major, chase, scene, eve...  negative\n",
       "3      [jane, austen, would, definitely, approve, one...  positive\n",
       "4      [expectations, somewhat, high, went, see, movi...  negative\n",
       "...                                                  ...       ...\n",
       "24994  [barely, find, words, express, utterly, utterl...  negative\n",
       "24995  [directors, like, nacho, vigalondo, need, grea...  positive\n",
       "24996  [rita, hayworth, lights, screen, fun, fancy, d...  positive\n",
       "24997  [biggest, heroes, one, greatest, movies, ever,...  positive\n",
       "24998  [happened, see, promo, movie, spike, channel, ...  negative\n",
       "\n",
       "[24876 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c64b1964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize tokens with POS tagging\n",
    "def lemmatize_with_pos(tokens):\n",
    "    tagged_tokens = nltk.pos_tag(tokens)  # Perform POS tagging\n",
    "    lemmatized_tokens = []\n",
    "    for token, tag in tagged_tokens:\n",
    "        # Convert POS tag to WordNet POS tag\n",
    "        wn_tag = nltk.corpus.wordnet.NOUN\n",
    "        if tag.startswith('J'):\n",
    "            wn_tag = nltk.corpus.wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            wn_tag = nltk.corpus.wordnet.VERB\n",
    "        elif tag.startswith('R'):\n",
    "            wn_tag = nltk.corpus.wordnet.ADV\n",
    "        # Lemmatize token with POS tag\n",
    "        lemma = lemmatizer.lemmatize(token, pos=wn_tag)\n",
    "        lemmatized_tokens.append(lemma)\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply lemmatization to your dataset column\n",
    "dataset['review'] = dataset['review'].apply(lemmatize_with_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbb93062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[really, liked, summerslam, due, look, arena, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[many, television, show, appeal, quite, many, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[film, quickly, get, major, chase, scene, ever...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[jane, austen, would, definitely, approve, one...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[expectation, somewhat, high, go, see, movie, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>[barely, find, word, express, utterly, utterly...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>[director, like, nacho, vigalondo, need, great...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>[rita, hayworth, light, screen, fun, fancy, de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>[big, hero, one, great, movie, ever, good, sto...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>[happen, see, promo, movie, spike, channel, la...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      [really, liked, summerslam, due, look, arena, ...  positive\n",
       "1      [many, television, show, appeal, quite, many, ...  positive\n",
       "2      [film, quickly, get, major, chase, scene, ever...  negative\n",
       "3      [jane, austen, would, definitely, approve, one...  positive\n",
       "4      [expectation, somewhat, high, go, see, movie, ...  negative\n",
       "...                                                  ...       ...\n",
       "24994  [barely, find, word, express, utterly, utterly...  negative\n",
       "24995  [director, like, nacho, vigalondo, need, great...  positive\n",
       "24996  [rita, hayworth, light, screen, fun, fancy, de...  positive\n",
       "24997  [big, hero, one, great, movie, ever, good, sto...  positive\n",
       "24998  [happen, see, promo, movie, spike, channel, la...  negative\n",
       "\n",
       "[24876 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73a45b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(tokens):\n",
    "    return ' '.join(token for token in tokens)\n",
    "\n",
    "dataset['review'] = dataset['review'].apply(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2c65ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size = 0.2, shuffle = True) # Train Split 80-20\n",
    "tfidfvect = TfidfVectorizer(analyzer = \"word\", ngram_range = (1,2), min_df = 10, max_features = 5000)\n",
    "\n",
    "x_train_tfidf = tfidfvect.fit_transform(train['review']).toarray()\n",
    "x_test_tfidf = tfidfvect.transform(test['review']).toarray()\n",
    "\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9a937c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(19900, 5000))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c8a6689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23568    positive\n",
       "21784    negative\n",
       "17310    positive\n",
       "12148    negative\n",
       "23597    positive\n",
       "           ...   \n",
       "24528    negative\n",
       "9340     positive\n",
       "24171    negative\n",
       "14768    positive\n",
       "14473    negative\n",
       "Name: sentiment, Length: 19900, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ac625cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text analytics is the automated process of translating large volumes of unstructured text into quantitative data to uncover insights, trends, and patterns. Combined with data visualization tools, this technique enables companies to understand the story behind the numbers and make better decisions.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"C:/Users/Student/Desktop/DAY 01/Sample.txt\")\n",
    "data_2 = file.read()\n",
    "data_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a12d678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to C:/Users/Student/Desktop/DAY 01/Book1.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the raw CSV file\n",
    "url = \"https://raw.githubusercontent.com/omaarelsherif/Movie-Reviews-Sentiment-Analysis-Using-Machine-Learning/main/Dataset/IMDB.csv\"\n",
    "\n",
    "# Fetch the content from the URL\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Check if the request was successful\n",
    "\n",
    "# Save the content to a CSV file\n",
    "csv_file_path = \"C:/Users/Student/Desktop/DAY 01/Book1.csv\"\n",
    "with open(csv_file_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"Data has been saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "323275c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text analytics is the automated process of translating large volumes of unstructured text into quantitative data to uncover insights, trends, and patterns.',\n",
       " 'Combined with data visualization tools, this technique enables companies to understand the story behind the numbers and make better decisions.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "sentences = nltk.sent_tokenize(data_2)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f42ba2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c4b6dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text',\n",
       " 'analytics',\n",
       " 'is',\n",
       " 'the',\n",
       " 'automated',\n",
       " 'process',\n",
       " 'of',\n",
       " 'translating',\n",
       " 'large',\n",
       " 'volumes',\n",
       " 'of',\n",
       " 'unstructured',\n",
       " 'text',\n",
       " 'into',\n",
       " 'quantitative',\n",
       " 'data',\n",
       " 'to',\n",
       " 'uncover',\n",
       " 'insights',\n",
       " ',',\n",
       " 'trends',\n",
       " ',',\n",
       " 'and',\n",
       " 'patterns',\n",
       " '.',\n",
       " 'Combined',\n",
       " 'with',\n",
       " 'data',\n",
       " 'visualization',\n",
       " 'tools',\n",
       " ',',\n",
       " 'this',\n",
       " 'technique',\n",
       " 'enables',\n",
       " 'companies',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'the',\n",
       " 'story',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'numbers',\n",
       " 'and',\n",
       " 'make',\n",
       " 'better',\n",
       " 'decisions',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(data_2)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e01fea6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[really, liked, summerslam, due, look, arena, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[many, television, show, appeal, quite, many, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[film, quickly, get, major, chase, scene, ever...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[jane, austen, would, definitely, approve, one...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[expectation, somewhat, high, go, see, movie, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>[barely, find, word, express, utterly, utterly...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>[director, like, nacho, vigalondo, need, great...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>[rita, hayworth, light, screen, fun, fancy, de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>[big, hero, one, great, movie, ever, good, sto...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>[happen, see, promo, movie, spike, channel, la...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      [really, liked, summerslam, due, look, arena, ...  positive\n",
       "1      [many, television, show, appeal, quite, many, ...  positive\n",
       "2      [film, quickly, get, major, chase, scene, ever...  negative\n",
       "3      [jane, austen, would, definitely, approve, one...  positive\n",
       "4      [expectation, somewhat, high, go, see, movie, ...  negative\n",
       "...                                                  ...       ...\n",
       "24994  [barely, find, word, express, utterly, utterly...  negative\n",
       "24995  [director, like, nacho, vigalondo, need, great...  positive\n",
       "24996  [rita, hayworth, light, screen, fun, fancy, de...  positive\n",
       "24997  [big, hero, one, great, movie, ever, good, sto...  positive\n",
       "24998  [happen, see, promo, movie, spike, channel, la...  negative\n",
       "\n",
       "[24876 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ed6cd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize tokens with POS tagging\n",
    "def lemmatize_with_pos(tokens):\n",
    "    tagged_tokens = nltk.pos_tag(tokens)  # Perform POS tagging\n",
    "    lemmatized_tokens = []\n",
    "    for token, tag in tagged_tokens:\n",
    "        # Convert POS tag to WordNet POS tag\n",
    "        wn_tag = nltk.corpus.wordnet.NOUN\n",
    "        if tag.startswith('J'):\n",
    "            wn_tag = nltk.corpus.wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            wn_tag = nltk.corpus.wordnet.VERB\n",
    "        elif tag.startswith('R'):\n",
    "            wn_tag = nltk.corpus.wordnet.ADV\n",
    "        # Lemmatize token with POS tag\n",
    "        lemma = lemmatizer.lemmatize(token, pos=wn_tag)\n",
    "        lemmatized_tokens.append(lemma)\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply lemmatization to your dataset column\n",
    "dataset['review'] = dataset['review'].apply(lemmatize_with_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a34a089e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[really, liked, summerslam, due, look, arena, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[many, television, show, appeal, quite, many, ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[film, quickly, get, major, chase, scene, ever...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[jane, austen, would, definitely, approve, one...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[expectation, somewhat, high, go, see, movie, ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>[barely, find, word, express, utterly, utterly...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>[director, like, nacho, vigalondo, need, great...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>[rita, hayworth, light, screen, fun, fancy, de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>[big, hero, one, great, movie, ever, good, sto...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>[happen, see, promo, movie, spike, channel, la...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      [really, liked, summerslam, due, look, arena, ...  positive\n",
       "1      [many, television, show, appeal, quite, many, ...  positive\n",
       "2      [film, quickly, get, major, chase, scene, ever...  negative\n",
       "3      [jane, austen, would, definitely, approve, one...  positive\n",
       "4      [expectation, somewhat, high, go, see, movie, ...  negative\n",
       "...                                                  ...       ...\n",
       "24994  [barely, find, word, express, utterly, utterly...  negative\n",
       "24995  [director, like, nacho, vigalondo, need, great...  positive\n",
       "24996  [rita, hayworth, light, screen, fun, fancy, de...  positive\n",
       "24997  [big, hero, one, great, movie, ever, good, sto...  positive\n",
       "24998  [happen, see, promo, movie, spike, channel, la...  negative\n",
       "\n",
       "[24876 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ab9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(tokens):\n",
    "    return ' '.join(token for token in tokens)\n",
    "\n",
    "dataset['review'] = dataset['review'].apply(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c41d9383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>really liked summerslam due look arena curtain...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many television show appeal quite many differe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film quickly get major chase scene ever increa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jane austen would definitely approve onegwynet...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expectation somewhat high go see movie think s...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>barely find word express utterly utterly awful...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>director like nacho vigalondo need great outle...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>rita hayworth light screen fun fancy delightfu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>big hero one great movie ever good story great...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>happen see promo movie spike channel last nigh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      really liked summerslam due look arena curtain...  positive\n",
       "1      many television show appeal quite many differe...  positive\n",
       "2      film quickly get major chase scene ever increa...  negative\n",
       "3      jane austen would definitely approve onegwynet...  positive\n",
       "4      expectation somewhat high go see movie think s...  negative\n",
       "...                                                  ...       ...\n",
       "24994  barely find word express utterly utterly awful...  negative\n",
       "24995  director like nacho vigalondo need great outle...  positive\n",
       "24996  rita hayworth light screen fun fancy delightfu...  positive\n",
       "24997  big hero one great movie ever good story great...  positive\n",
       "24998  happen see promo movie spike channel last nigh...  negative\n",
       "\n",
       "[24876 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "461775f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size = 0.2, shuffle = True) # Train Split 80-20\n",
    "tfidfvect = TfidfVectorizer(analyzer = \"word\", ngram_range = (1,2), min_df = 10, max_features = 5000)\n",
    "\n",
    "x_train_tfidf = tfidfvect.fit_transform(train['review']).toarray()\n",
    "x_test_tfidf = tfidfvect.transform(test['review']).toarray()\n",
    "\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53a11ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11036776, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.10016898, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], shape=(19900, 5000))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dd3df53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1084     positive\n",
       "18349    negative\n",
       "4925     positive\n",
       "18708    negative\n",
       "8078     positive\n",
       "           ...   \n",
       "16871    negative\n",
       "10394    negative\n",
       "16329    negative\n",
       "11544    positive\n",
       "21484    negative\n",
       "Name: sentiment, Length: 19900, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c1acb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.8617188660833677\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86      2499\n",
      "    positive       0.85      0.87      0.86      2477\n",
      "\n",
      "    accuracy                           0.86      4976\n",
      "   macro avg       0.86      0.86      0.86      4976\n",
      "weighted avg       0.86      0.86      0.86      4976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train_tfidf, y_train)\n",
    "y_pred_1 = mnb.predict(x_test_tfidf)\n",
    "print('F1 Score: ', f1_score(y_test, y_pred_1, average = 'weighted'))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3609b3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.8904578065103573\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      2499\n",
      "    positive       0.88      0.90      0.89      2477\n",
      "\n",
      "    accuracy                           0.89      4976\n",
      "   macro avg       0.89      0.89      0.89      4976\n",
      "weighted avg       0.89      0.89      0.89      4976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_tfidf, y_train)\n",
    "y_pred_2 = lr.predict(x_test_tfidf)\n",
    "print('F1 Score: ', f1_score(y_test, y_pred_2, average = 'weighted'))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec71535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.8468589645766765\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.85      2499\n",
      "    positive       0.85      0.84      0.85      2477\n",
      "\n",
      "    accuracy                           0.85      4976\n",
      "   macro avg       0.85      0.85      0.85      4976\n",
      "weighted avg       0.85      0.85      0.85      4976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train_tfidf, y_train)\n",
    "y_pred_3 = rf.predict(x_test_tfidf)\n",
    "print('F1 Score: ', f1_score(y_test, y_pred_3, average = 'weighted'))\n",
    "print('Classification Report: \\n', classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "579957fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e979bcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results of MNB:  0.8519095477386935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_results = cross_val_score(mnb, x_train_tfidf, y_train, cv = skf)\n",
    "\n",
    "# CV Results\n",
    "print (\"CV Results of MNB: \", cv_results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61cb1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange\n",
    "param_grid = {\n",
    "    'penalty': [\"l1\", \"l2\", \"elasticnet\"],\n",
    "    'solver': ['saga', 'liblinear', 'lbfgs'],\n",
    "    'class_weight': ['balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adeeb022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "20 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1228, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 72, in _check_solver\n",
      "    raise ValueError(\n",
      "        f\"Only 'saga' solver supports elasticnet penalty, got solver={solver}.\"\n",
      "    )\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Student\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [0.87019487 0.87009473        nan 0.87891354 0.87891354 0.87871178\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters of LR:  {'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best F1 Score of LR:  0.8789135433915171\n"
     ]
    }
   ],
   "source": [
    "grid_rf = GridSearchCV(lr, param_grid, scoring = 'f1_weighted', cv = skf)\n",
    "grid_rf.fit(x_train_tfidf, y_train)\n",
    "print(\"Best Parameters of LR: \", grid_rf.best_params_)\n",
    "print(\"Best F1 Score of LR: \", grid_rf.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
